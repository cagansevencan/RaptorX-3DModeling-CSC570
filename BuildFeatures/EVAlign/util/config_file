# Sample configuration file for evcouplings monomer protein prediction pipeline.
# This file determines all aspects of the computation:
# - which compute environment to use
# - which stages of the pipeline to run
# - what the settings for each of the stages are

# Minimal settings required before this configuration can be executed:
# - set your environment, paths to tools and databases (at the end of this file)
# - under "global", set prefix and sequence_id
# - run it! :)

# Configuration rules:
# 1) Global settings override settings for stages
# 2) Outputs of a stage are merged into "global" and fed into the input of subsequent stages
#    (e.g., the alignment_file output of align will be used by the alignment_file input of couplings)
# 3) All settings are explicitly specified here. No hidden defaults in code.
# 4) Each stage is also passed the parameters in the "databases" and "tools" sections

pipeline: protein_monomer

# which stages of workflow to run. Uncomment downstream stages using # (however, no stage can be run before the previous
# stage has been run)
stages:
    - align
#    - couplings
#    - compare
#    - mutate
#    - fold

# Global job settings (which protein, region). These will override settings of the same name in each of the stages.
# These are typically the settings you want to modify for each of your jobs, together with some settings in the align stage.
global:
    # mandatory output prefix of the job (e.g. output/HRAS will store outputs in folder "output", using files prefixed with "HRAS")
    prefix: output/WSTEST

    # mandatory sequence identifier (mandatory, even if sequence_file is given)
    sequence_id: 1pazA

    # optional FASTA file with target sequence (if blank, will fetch try to fetch sequence_id from databases.sequence_download_url)
    # if sequence_file is set, sequence_id must be defined, but can be arbitrary identifier (does not have to match ID in file)
    sequence_file: /home/RaptorX/wstest/JackHmmer_Test/1pazA.fasta

    # cut to subregion of sequence (specify as list, e.g. [24, 286], leave blank for full sequence)
    region:

    # Clustering threshold for downweighting redudant sequences (Meff computation). E.g. 0.8 will cluster sequences
    # at a 80% sequence identity cutoff
    theta: 0.8

    # number of cores to use. If running through evcouplings application, will be overriden by environment.cores
    cpu: 1

# Specify multiple batch jobs (if empty, only a single job will be run). Each entry (e.g. b_0.75) will be appended to
# global.prefix to uniquely identify the subjob. Parameters for individual stages that should be overridden for each
# subjob have to be specified, for all other parameters jobs share the same values.
batch:
#    _b0.75:
#       align: {domain_threshold: 0.75, sequence_threshold: 0.75}
#    _b0.3:
#       align: {domain_threshold: 0.3, sequence_threshold: 0.3}

# Sequence alignment generation/processing.
align:
    # standard: iterative sequence search and postprocessing using jackhmmer.
    protocol: standard

    # The following fields usually do not need to be set, since "global" defines them.
    # prefix:
    # sequence_id:
    # sequence_file:
    # region:
    # theta:

    # index of first residue in sequence_id / sequence_file. This can be used to renumber sequences that already have
    # been cut to a subsequence
    first_index: 1

    # Use bitscore threshold instead of E-value threshold for sequence search
    use_bitscores: True

    # jackhmmer domain- and sequence-level inclusion thresholds.
    # if use_bitscores is True:
    # - floating point number will be interpreted as a relative bitscore threshold (bits/residue)
    # - integer will be interpreted as an absolute bitscore threshold
    # if use_bitscore is False:
    # - mantissa-exponent string or float will be interpreted literally
    # - integer will be interpreted as negative of the exponent (10 -> 1E-10)
    domain_threshold: 0.5
    sequence_threshold: 0.5

    # number of jackhmmer iterations
    iterations: 5

    # sequence database (specify possible databases and paths in "databases" section below)
    database: uniref90

    # compute the redundancy-reduced number of effective sequences (M_eff) already in the alignment stage.
    # To save compute time, this computation is normally carried out in the couplings stage
    compute_num_effective_seqs: False

    # Filter sequence alignment at this % sequence identity cutoff. Can be used to cut computation time in
    # the couplings stage (e.g. set to 95 to remove any sequence that is more than 95% identical to a sequence
    # already present in the alignment). If blank, no filtering. If filtering, HHfilter must be installed.
    seqid_filter:

    # Only keep sequences that align to at least x% of the target sequence (i.e. remove fragments)
    minimum_sequence_coverage: 50

    # Only include alignment columns with at least x% residues (rather than gaps) during model inference
    minimum_column_coverage: 70

    # Create a file with extracted annotation from UniRef/UniProt sequence FASTA headers
    extract_annotation: True
    cpu:

    # set to True to turn of jackhmmer bias correction
    nobias: False

    # if align stage has been run previously, reuse the generated raw sequence alignment coming out of jackhmmer
    reuse_alignment: True

    # create checkpoint files of HMM and aligment after each iteration
    checkpoints_hmm: False
    checkpoints_ali: False

# Alternative protocol: reuse existing alignment and apply postprocessing to generate alignment that is consistent
# with pipeline requirements. Uncomment, and comment all values in align section above to enable the "existing" protocol
#    protocol: existing
#    prefix:
#    # Path of input alignment. Alignment needs to contain region in form SEQID/start-end, or first_index must be set
#    input_alignment:
#    sequence_id:
#    first_index:
#    compute_num_effective_seqs: False
#    theta:
#    seqid_filter:
#    minimum_sequence_coverage: 50
#    minimum_column_coverage: 70
#    extract_annotation: True

# Inference of evolutionary couplings from sequence alignment

# These settings allow job status tracking using a database, and result collection in an archive
management:
    # URI of database
    database_uri:

    # unique job identifier
    job_name:

    # add the following output files to results archive
    archive: [target_sequence_file, statistics_file, alignment_file, frequencies_file, ec_file, ec_longrange_file,
              model_file, enrichment_file, evzoom_file, enrichment_pml_files, ec_lines_pml_file, contact_map_files,
              ec_compared_all_file, ec_compared_longrange_file, remapped_pdb_files, mutations_epistatic_pml_files,
              mutation_matrix_file, mutation_matrix_plot_files, secondary_structure_pml_file, folding_ec_file,
              folded_structure_files, folding_ranking_file, folding_comparison_file, folding_individual_comparison_files,
              ec_lines_compared_pml_file, pdb_structure_hits_file, sec_struct_file]

    # Delete the following output files after running the job if you don't need them, to save disk space.
    # Note that this may jeopardize your ability to rerun parts of the job if intermediate files are missing.
    # The following, deactivated default deletes the biggest output files.
    # delete: [raw_alignment_file, model_file]

# Computational environment for batch jobs (using evcouplings command line application)
environment:
    # current options for engine: lsf, local (for local, only set cores and leave all other fields blank)
    # If your batch engine of choice (SGE, Slurm, Torque) is not available yet, please consider contributing by
    # implementing it and submitting a pull request!
    # Note that "cores" will override the "cpu" parameter for "global"
    engine: lsf
    queue: mcore
    cores: 2
    memory: 15000
    time: 48:0

    # command that will be executed before running actual computation (can be used to set up environment)
    configuration:
        - source activate evcouplings_env

# Paths to databases used by evcouplings.
databases:
    # Sequence databases (only download the ones you want to use). You can also specify arbitrary databases in FASTA format
    # using a database name of your choice here)

     uniref100: /home/RaptorX/wstest/JackHmmer_Test/uniref100.fasta
#     uniref100: /home/RaptorX/wstest/JackHmmer_Test/bc100_seqres_fasta 
#
#    uniprot: /groups/marks/databases/jackhmmer/uniprot/uniprot_current.fasta
#    uniref100: /groups/marks/databases/jackhmmer/uniref100/uniref100_current.fasta

     uniref90: /home/RaptorX/wstest/JackHmmer_Test/uniref90.fasta
#    uniref90: /groups/marks/databases/jackhmmer/uniref90/uniref90_current.fasta


    # URL do download sequences if sequence_file is not given. {} will be replaced by sequence_id.
#    sequence_download_url: /home/RaptorX/wstest/JackHmmer_Test/1pazA.fasta 

    # Directory with PDB MMTF structures (leave blank to fetch structures from web)
#    pdb_mmtf_dir:

    # SIFTS mapping information. Point to file paths in an existing directory, and if these files do not exist, they will be
    # automatically generated and saved at the given file path (this may take a while).
    # Periodically delete these files to more recent versions of SIFTS are used.
#    sifts_mapping_table: /groups/marks/databases/SIFTS/pdb_chain_uniprot_plus_current.csv
#    sifts_sequence_db: /groups/marks/databases/SIFTS/pdb_chain_uniprot_plus_current.fasta

# Paths to external tools used by evcouplings. Please refer to README.md for installation instructions and which tools are required.
tools:
     jackhmmer: /home/RaptorX/wstest/JackHmmer_Test/jackhmmer
#    jackhmmer: /groups/marks/pipelines/evcouplings/software/hmmer-3.1b2-linux-intel-x86_64/binaries/jackhmmer
#    plmc: /groups/marks/pipelines/evcouplings/software/plmc/bin/plmc
#    hmmbuild: /groups/marks/pipelines/evcouplings/software/hmmer-3.1b2-linux-intel-x86_64/binaries/hmmbuild
#    hmmsearch: /groups/marks/pipelines/evcouplings/software/hmmer-3.1b2-linux-intel-x86_64/binaries/hmmsearch
     hhfilter: /home/RaptorX/GitBucket/TGT_Package/hhsuite/bin/hhfilter_bad #-> this can be NULL 
#    hhfilter: /groups/marks/pipelines/evcouplings/software/hh-suite/bin/hhfilter
#    psipred: /groups/marks/software/runpsipred_o2
#    cns: /groups/marks/pipelines/evcouplings/software/cns_solve_1.21/intel-x86_64bit-linux/bin/cns
#    maxcluster: /groups/marks/pipelines/evcouplings/software/maxcluster64bit

